{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:02<00:00, 79.92it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Evaluation MSE: 1.1694552635372049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:01<00:00, 111.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Evaluation MSE: 0.9055586356925464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:01<00:00, 114.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Evaluation MSE: 0.8408118692317801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "from matrix_factorization import * \n",
    "from evaluation_metrics import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "full_datadata = pd.read_csv(\"../data/ratings.csv\")\n",
    "train_data = pd.read_csv(\"../data/splitted_data_small/train.csv\")\n",
    "test_data = pd.read_csv(\"../data/splitted_data_small/test.csv\")\n",
    "eval_data = pd.read_csv(\"../data/splitted_data_small/val.csv\")\n",
    "mf = MatrixFactorization(num_epochs=3)\n",
    "mf.train_loop(full_datadata, train_data, eval_data)\n",
    "mse = mf.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error:  0.8464482129708163\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean Squared Error: \", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Precision@10: 0.44279897885450664\n",
      "Mean Recall@10: 0.41269334048782985\n",
      "Mean F1 Score@10: 0.4251625575021161\n",
      "Mean Average Precision@10: 0.45522260689427607\n"
     ]
    }
   ],
   "source": [
    "k = 10\n",
    "threshold = 4\n",
    "test_data['predicted_rating'] = mf.predict(test_data)\n",
    "\n",
    "# Evaluate the recommendations\n",
    "mean_precision, mean_recall, mean_f1, map_k = evaluate_recommendations(test_data, threshold, k, 10)\n",
    "print(f\"Mean Precision@{k}: {mean_precision}\")\n",
    "print(f\"Mean Recall@{k}: {mean_recall}\")\n",
    "print(f\"Mean F1 Score@{k}: {mean_f1}\")\n",
    "print(f\"Mean Average Precision@{k}: {map_k}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Another simple baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>predicted_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1481</td>\n",
       "      <td>7319</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.276089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>843</td>\n",
       "      <td>8482</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.590738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>860</td>\n",
       "      <td>797</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.836284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>475</td>\n",
       "      <td>726</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.375315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>225</td>\n",
       "      <td>542</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.405603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22393</th>\n",
       "      <td>1990</td>\n",
       "      <td>584</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.250353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22394</th>\n",
       "      <td>62</td>\n",
       "      <td>1376</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.563478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22395</th>\n",
       "      <td>740</td>\n",
       "      <td>2590</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.894206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22396</th>\n",
       "      <td>612</td>\n",
       "      <td>18</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.230125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22397</th>\n",
       "      <td>1657</td>\n",
       "      <td>5155</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.248450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22398 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id  book_id  rating  predicted_rating\n",
       "0         1481     7319     5.0          3.276089\n",
       "1          843     8482     5.0          5.590738\n",
       "2          860      797     4.0          3.836284\n",
       "3          475      726     4.0          4.375315\n",
       "4          225      542     3.0          3.405603\n",
       "...        ...      ...     ...               ...\n",
       "22393     1990      584     3.0          4.250353\n",
       "22394       62     1376     5.0          3.563478\n",
       "22395      740     2590     3.0          3.894206\n",
       "22396      612       18     5.0          2.230125\n",
       "22397     1657     5155     5.0          4.248450\n",
       "\n",
       "[22398 rows x 4 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = train_data['rating'].mean()\n",
    "std = train_data['rating'].std()\n",
    "\n",
    "# for each user sample rating from normal distribution\n",
    "test_data['predicted_rating'] = np.random.normal(mean, std, test_data.shape[0])\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Precision@10: 0.4832497598005352\n",
      "Mean Recall@10: 0.461446289731272\n",
      "Mean F1 Score@10: 0.47055431603784326\n",
      "Mean Average Precision@10: 0.48395608739113827\n"
     ]
    }
   ],
   "source": [
    "k = 10\n",
    "threshold = 4\n",
    "\n",
    "# Evaluate the recommendations\n",
    "mean_precision, mean_recall, mean_f1, map_k = evaluate_recommendations(test_data, threshold, k, 10)\n",
    "print(f\"Mean Precision@{k}: {mean_precision}\")\n",
    "print(f\"Mean Recall@{k}: {mean_recall}\")\n",
    "print(f\"Mean F1 Score@{k}: {mean_f1}\")\n",
    "print(f\"Mean Average Precision@{k}: {map_k}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
