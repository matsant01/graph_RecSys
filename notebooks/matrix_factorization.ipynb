{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4670/4670 [00:23<00:00, 197.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Evaluation MSE: 0.7689731162481963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4670/4670 [00:23<00:00, 197.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Evaluation MSE: 0.761143251298259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "from matrix_factorization import * \n",
    "from evaluation_metrics import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "full_datadata = pd.read_csv(\"../data/ratings.csv\")\n",
    "train_data = pd.read_csv(\"../data/splitted_data/train.csv\")\n",
    "test_data = pd.read_csv(\"../data/splitted_data/test.csv\")\n",
    "eval_data = pd.read_csv(\"../data/splitted_data/val.csv\")\n",
    "mf = MatrixFactorization(num_epochs=2)\n",
    "mf.train_loop(full_datadata, train_data, eval_data)\n",
    "mse = mf.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error:  0.759675919124853\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean Squared Error: \", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Precision@5: 0.7667857501948069\n",
      "Mean Recall@5: 0.5586681536570322\n",
      "Mean F1 Score@5: 0.6102003344248862\n"
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "test_data['predicted_rating'] = mf.predict(test_data)\n",
    "top_k_recommendations = get_top_k_recommendations(test_data, k)\n",
    "actual_items = get_actual_items(test_data, 4) # ground truth\n",
    "\n",
    "# Evaluate the recommendations\n",
    "mean_precision, mean_recall, mean_f1 = evaluate_recommendations(top_k_recommendations, actual_items, k)\n",
    "print(f\"Mean Precision@{k}: {mean_precision}\")\n",
    "print(f\"Mean Recall@{k}: {mean_recall}\")\n",
    "print(f\"Mean F1 Score@{k}: {mean_f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Another simple baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>predicted_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45499</td>\n",
       "      <td>5550</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.144333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42306</td>\n",
       "      <td>7344</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.703423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>43412</td>\n",
       "      <td>3952</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.105445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19263</td>\n",
       "      <td>6289</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.104966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25831</td>\n",
       "      <td>3636</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.256068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597642</th>\n",
       "      <td>37136</td>\n",
       "      <td>984</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.052190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597643</th>\n",
       "      <td>45477</td>\n",
       "      <td>646</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.850338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597644</th>\n",
       "      <td>30726</td>\n",
       "      <td>829</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.250500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597645</th>\n",
       "      <td>45579</td>\n",
       "      <td>536</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.234927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597646</th>\n",
       "      <td>6676</td>\n",
       "      <td>3475</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.998564</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>597647 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  book_id  rating  predicted_rating\n",
       "0         45499     5550     4.0          2.144333\n",
       "1         42306     7344     3.0          2.703423\n",
       "2         43412     3952     4.0          3.105445\n",
       "3         19263     6289     4.0          3.104966\n",
       "4         25831     3636     5.0          4.256068\n",
       "...         ...      ...     ...               ...\n",
       "597642    37136      984     3.0          4.052190\n",
       "597643    45477      646     5.0          5.850338\n",
       "597644    30726      829     5.0          4.250500\n",
       "597645    45579      536     5.0          3.234927\n",
       "597646     6676     3475     4.0          1.998564\n",
       "\n",
       "[597647 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = train_data['rating'].sample(1000000).mean()\n",
    "std = train_data['rating'].sample(1000000).std()\n",
    "\n",
    "# for each user sample rating from normal distribution\n",
    "test_data['predicted_rating'] = np.random.normal(mean, std, test_data.shape[0])\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Precision@2: 0.8206844045520115\n",
      "Mean Recall@2: 0.828934490841447\n",
      "Mean F1 Score@2: 0.7990175166204978\n"
     ]
    }
   ],
   "source": [
    "k = 2\n",
    "smaller_test = test_data.sample(100000)\n",
    "top_k_recommendations = get_top_k_recommendations(smaller_test, k)\n",
    "actual_items = get_actual_items(smaller_test, 4) # ground truth\n",
    "\n",
    "# Evaluate the recommendations\n",
    "mean_precision, mean_recall, mean_f1 = evaluate_recommendations(top_k_recommendations, actual_items, k)\n",
    "print(f\"Mean Precision@{k}: {mean_precision}\")\n",
    "print(f\"Mean Recall@{k}: {mean_recall}\")\n",
    "print(f\"Mean F1 Score@{k}: {mean_f1}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
