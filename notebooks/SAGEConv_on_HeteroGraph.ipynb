{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch_geometric as pyg\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = 'mps'\n",
    "else:\n",
    "    device = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_books = pd.read_csv('../data/books.csv')[['book_id', 'title', 'authors']]    # TODO: think about using also the columns\n",
    "df_ratings = pd.read_csv('../data/ratings.csv')\n",
    "\n",
    "print(df_books.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create features\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2', device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Books features\n",
    "df_books[\"text_to_embed\"] = \"Title: \" + df_books[\"title\"] + \" Authors: \" + df_books[\"authors\"]\n",
    "with torch.no_grad():\n",
    "    titles_emb = model.encode(df_books['text_to_embed'].values, device=device, show_progress_bar=True, batch_size=32)\n",
    "    \n",
    "books_features = torch.tensor(titles_emb)\n",
    "print(\"Books features shape:\", books_features.shape)\n",
    "\n",
    "# Users features: as we don't have any information we will use random features\n",
    "users_features = torch.rand(df_ratings['user_id'].nunique(), 768, device=device)\n",
    "print(\"Users features shape:\", users_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two dataframes keeping user_id, book_id, rating, title, authors\n",
    "df_ratings = pd.merge(df_ratings, df_books, on='book_id')\n",
    "df_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping from the user_id to a unique consecutive value in the range [0, num_users]:\n",
    "unique_user_id = df_ratings['user_id'].unique()\n",
    "unique_user_id = pd.DataFrame(data={\n",
    "    'user_id': unique_user_id, \n",
    "    'mapped_user_id': pd.RangeIndex(len(unique_user_id))\n",
    "    })\n",
    "print(\"Mapping of user IDs to consecutive values:\")\n",
    "print(\"==========================================\")\n",
    "print(unique_user_id.head())\n",
    "print()\n",
    "\n",
    "# Create a mapping from the book_id to a unique consecutive value in the range [0, num_books]:\n",
    "unique_book_id = df_ratings['book_id'].unique()\n",
    "unique_book_id = pd.DataFrame(data={\n",
    "    'book_id': unique_book_id,\n",
    "    'mapped_book_id': pd.RangeIndex(len(unique_book_id))\n",
    "    })\n",
    "print(\"Mapping of movie IDs to consecutive values:\")\n",
    "print(\"===========================================\")\n",
    "print(unique_book_id.head())\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings = df_ratings.merge(unique_user_id, on='user_id')\n",
    "df_ratings = df_ratings.merge(unique_book_id, on='book_id')\n",
    "\n",
    "# With this, we are ready to create the edge_index representation in COO format\n",
    "# following the PyTorch Geometric semantics:\n",
    "edge_index = torch.stack([\n",
    "    torch.tensor(df_ratings['mapped_user_id'].values), \n",
    "    torch.tensor(df_ratings['mapped_book_id'].values)]\n",
    "    , dim=0)\n",
    "\n",
    "print(edge_index[:, :10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import HeteroData\n",
    "\n",
    "# Create the heterogeneous graph data object:\n",
    "data = HeteroData()\n",
    "\n",
    "# Add the user nodes:\n",
    "data['user'].x = torch.tensor(users_features, dtype=torch.long)  # (num_users, num_users_features)\n",
    "\n",
    "# Add the book nodes:\n",
    "data['book'].x = torch.tensor(titles_emb, dtype=torch.long)  # (num_books, num_books_features)\n",
    "\n",
    "# Add the rating edges:\n",
    "data['user', 'rates', 'book'].edge_index = edge_index  # (2, num_ratings)\n",
    "\n",
    "# Add the rating labels:\n",
    "rating = torch.from_numpy(df_ratings['rating'].values)\n",
    "data['user', 'rates', 'book'].edge_label = rating  # [num_ratings]\n",
    "\n",
    "# We also need to make sure to add the reverse edges from books to users\n",
    "# in order to let a GNN be able to pass messages in both directions.\n",
    "# We can leverage the `T.ToUndirected()` transform for this from PyG:\n",
    "data = T.ToUndirected()(data)\n",
    "\n",
    "# With the above transformation we also got reversed labels for the edges.\n",
    "# We remove them\n",
    "del data['book', 'rev_rates', 'user'].edge_label\n",
    "\n",
    "assert data['user'].num_nodes == len(unique_user_id)\n",
    "assert data['user', 'rates', 'book'].num_edges == len(df_ratings)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data, test_data = T.RandomLinkSplit(\n",
    "    neg_sampling_ratio=0.0,\n",
    "    edge_types=[('user', 'rates', 'book')],\n",
    "    rev_edge_types=[('book', 'rev_rates', 'user')],\n",
    ")(data)\n",
    "train_data, val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import SAGEConv, to_hetero\n",
    "\n",
    "class GNNEncoder(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv((-1, -1), hidden_channels)\n",
    "        self.conv2 = SAGEConv((-1, -1), out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "\n",
    "class EdgeDecoder(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.lin1 = torch.nn.Linear(2 * hidden_channels, hidden_channels)\n",
    "        self.lin2 = torch.nn.Linear(hidden_channels, 1)\n",
    "\n",
    "    def forward(self, z_dict, edge_label_index):\n",
    "        row, col = edge_label_index\n",
    "        z = torch.cat([z_dict['user'][row], z_dict['movie'][col]], dim=-1)\n",
    "\n",
    "        z = self.lin1(z).relu()\n",
    "        z = self.lin2(z)\n",
    "        return z.view(-1)\n",
    "\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.encoder = GNNEncoder(hidden_channels, hidden_channels)\n",
    "        self.encoder = to_hetero(self.encoder, data.metadata(), aggr='sum')\n",
    "        self.decoder = EdgeDecoder(hidden_channels)\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict, edge_label_index):\n",
    "        z_dict = self.encoder(x_dict, edge_index_dict)\n",
    "        return self.decoder(z_dict, edge_label_index)\n",
    "\n",
    "\n",
    "model = Model(hidden_channels=10).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the data loader\n",
    "train_dataloader= NeighborLoader(\n",
    "    data=train_data,\n",
    "    num_neighbors={key: [10] * 2 for key in train_data.edge_types},\n",
    "    input_nodes=(\"user\", train_data[\"user\"].x),   # What if we use book?\n",
    "    batch_size=128,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in train_dataloader:\n",
    "    print(p)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loop\n",
    "def train(model, data_loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in data_loader:\n",
    "        batch = batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(batch.x_dict, batch.edge_index_dict, batch['user', 'rates', 'book'].edge_label_index)\n",
    "        loss = criterion(pred, batch['user', 'rates', 'book'].edge_label.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * batch.num_graphs\n",
    "    return total_loss / len(data_loader.dataset)\n",
    "\n",
    "# Testing Loop\n",
    "def test(model, data_loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            batch = batch.to(device)\n",
    "            pred = model(batch.x_dict, batch.edge_index_dict, batch['user', 'rates', 'book'].edge_label_index)\n",
    "            loss = criterion(pred, batch['user', 'rates', 'book'].edge_label.float())\n",
    "            total_loss += loss.item() * batch.num_graphs\n",
    "    return total_loss / len(data_loader.dataset)\n",
    "\n",
    "# Main training and testing routines\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train(model, train_dataloader, optimizer, criterion)\n",
    "    val_loss = test(model, val_data, criterion)\n",
    "    print(f'Epoch: {epoch+1}, Training Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}')\n",
    "\n",
    "# Optionally, after training, you can evaluate your model on the test dataset\n",
    "test_loss = test(model, test_data, criterion)\n",
    "print(f'Test Loss: {test_loss:.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "networkML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
