{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/network_ml/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch_geometric as pyg\n",
    "\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = 'mps'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['book_id', 'title', 'authors'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df_books = pd.read_csv('../data/books.csv')[['book_id', 'title', 'authors']]    # TODO: think about using also the columns\n",
    "\n",
    "df_ratings = pd.read_csv('../data/ratings.csv').sample(5000)  # TODO: remove the sampling on the final run\n",
    "# df_ratings = pd.read_csv('../data/ratings.csv')\n",
    "\n",
    "print(df_books.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create features\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2', device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 313/313 [00:40<00:00,  7.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Books features shape: torch.Size([10000, 384])\n"
     ]
    }
   ],
   "source": [
    "# Books features\n",
    "df_books[\"text_to_embed\"] = \"Title: \" + df_books[\"title\"] + \" Authors: \" + df_books[\"authors\"]\n",
    "with torch.no_grad():\n",
    "    titles_emb = model.encode(df_books['text_to_embed'].values, device=device, show_progress_bar=True, batch_size=32)\n",
    "    \n",
    "del model\n",
    "torch.cuda.empty_cache()    \n",
    "\n",
    "books_features = torch.tensor(titles_emb)\n",
    "print(\"Books features shape:\", books_features.shape)\n",
    "\n",
    "# Users features: as we don't have any information we will use random features\n",
    "# users_features = torch.rand(df_ratings['user_id'].nunique(), 768, device=device)\n",
    "# print(\"Users features shape:\", users_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding edges: 100%|██████████| 5000/5000 [00:00<00:00, 25466.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "degree centrality computed\n",
      "pagerank computed\n",
      "all metrics computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>degree</th>\n",
       "      <th>pagerank</th>\n",
       "      <th>average_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51773</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.099417</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10948</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046463</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1442</th>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.138085</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37891</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.034253</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21483</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052001</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         degree  pagerank  average_rating\n",
       "51773  0.000000  0.099417            0.50\n",
       "10948  0.000000  0.046463            1.00\n",
       "1442   0.066667  0.138085            1.00\n",
       "37891  0.000000  0.034253            0.75\n",
       "21483  0.000000  0.052001            0.25"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# embedding users\n",
    "\n",
    "# # Create a bipartite graph\n",
    "B = nx.Graph()\n",
    "# Add nodes with the node attribute \"bipartite\"\n",
    "B.add_nodes_from(df_ratings['user_id'].unique(), bipartite=0)  # Users\n",
    "B.add_nodes_from(df_ratings['book_id'].unique(), bipartite=1)  # Books\n",
    "\n",
    "# Add edges between users and books\n",
    "for _, row in tqdm(df_ratings.iterrows(), total=df_ratings.shape[0], desc=\"Adding edges\"):\n",
    "    B.add_edge(row['user_id'], row['book_id'], weight=row['rating'])\n",
    "\n",
    "# Compute metrics\n",
    "centrality = nx.degree_centrality(B)\n",
    "print('degree centrality computed')\n",
    "pagerank = nx.pagerank(B, weight='weight')\n",
    "print('pagerank computed')\n",
    "average_rating = df_ratings.groupby('user_id')['rating'].mean()\n",
    "print('all metrics computed')\n",
    "\n",
    "# # Prepare feature vectors for users\n",
    "features = pd.DataFrame(index=df_ratings['user_id'].unique())\n",
    "features['degree'] = [centrality[node] for node in features.index]\n",
    "features['pagerank'] = [pagerank[node] for node in features.index]\n",
    "features['average_rating'] = [average_rating.get(node, 0) for node in features.index]  # Add average ratings\n",
    "\n",
    "# # Normalize features\n",
    "scaler = MinMaxScaler()\n",
    "features_scaled = pd.DataFrame(scaler.fit_transform(features), index=features.index, columns=features.columns)\n",
    "\n",
    "# # Display the normalized features\n",
    "users_features = features_scaled.to_numpy(dtype=np.float32)\n",
    "\n",
    "features_scaled.head() \n",
    "\n",
    "# aprox 2 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>text_to_embed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51773</td>\n",
       "      <td>1076</td>\n",
       "      <td>3</td>\n",
       "      <td>The Nest</td>\n",
       "      <td>Cynthia D'Aprix Sweeney</td>\n",
       "      <td>Title: The Nest Authors: Cynthia D'Aprix Sweeney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10948</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>The Hunger Games (The Hunger Games, #1)</td>\n",
       "      <td>Suzanne Collins</td>\n",
       "      <td>Title: The Hunger Games (The Hunger Games, #1)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1442</td>\n",
       "      <td>3194</td>\n",
       "      <td>5</td>\n",
       "      <td>Sisterland</td>\n",
       "      <td>Curtis Sittenfeld</td>\n",
       "      <td>Title: Sisterland Authors: Curtis Sittenfeld</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37891</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>The Fellowship of the Ring (The Lord of the Ri...</td>\n",
       "      <td>J.R.R. Tolkien</td>\n",
       "      <td>Title: The Fellowship of the Ring (The Lord of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21483</td>\n",
       "      <td>453</td>\n",
       "      <td>2</td>\n",
       "      <td>Cold Mountain</td>\n",
       "      <td>Charles Frazier</td>\n",
       "      <td>Title: Cold Mountain Authors: Charles Frazier</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  book_id  rating  \\\n",
       "0    51773     1076       3   \n",
       "1    10948        1       5   \n",
       "2     1442     3194       5   \n",
       "3    37891       19       4   \n",
       "4    21483      453       2   \n",
       "\n",
       "                                               title                  authors  \\\n",
       "0                                           The Nest  Cynthia D'Aprix Sweeney   \n",
       "1            The Hunger Games (The Hunger Games, #1)          Suzanne Collins   \n",
       "2                                         Sisterland        Curtis Sittenfeld   \n",
       "3  The Fellowship of the Ring (The Lord of the Ri...           J.R.R. Tolkien   \n",
       "4                                      Cold Mountain          Charles Frazier   \n",
       "\n",
       "                                       text_to_embed  \n",
       "0   Title: The Nest Authors: Cynthia D'Aprix Sweeney  \n",
       "1  Title: The Hunger Games (The Hunger Games, #1)...  \n",
       "2       Title: Sisterland Authors: Curtis Sittenfeld  \n",
       "3  Title: The Fellowship of the Ring (The Lord of...  \n",
       "4      Title: Cold Mountain Authors: Charles Frazier  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge the two dataframes keeping user_id, book_id, rating, title, authors\n",
    "df_ratings = pd.merge(df_ratings, df_books, on='book_id')\n",
    "df_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping of user IDs to consecutive values:\n",
      "==========================================\n",
      "   user_id  mapped_user_id\n",
      "0    51773               0\n",
      "1    10948               1\n",
      "2     1442               2\n",
      "3    37891               3\n",
      "4    21483               4\n",
      "\n",
      "Mapping of book IDs to consecutive values:\n",
      "===========================================\n",
      "   book_id  mapped_book_id\n",
      "0     1076               0\n",
      "1        1               1\n",
      "2     3194               2\n",
      "3       19               3\n",
      "4      453               4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a mapping from the user_id to a unique consecutive value in the range [0, num_users]:\n",
    "unique_user_id = df_ratings['user_id'].unique()\n",
    "unique_user_id = pd.DataFrame(data={\n",
    "    'user_id': unique_user_id, \n",
    "    'mapped_user_id': pd.RangeIndex(len(unique_user_id))\n",
    "    })\n",
    "print(\"Mapping of user IDs to consecutive values:\")\n",
    "print(\"==========================================\")\n",
    "print(unique_user_id.head())\n",
    "print()\n",
    "\n",
    "# Create a mapping from the book_id to a unique consecutive value in the range [0, num_books]:\n",
    "unique_book_id = df_ratings['book_id'].unique()\n",
    "unique_book_id = pd.DataFrame(data={\n",
    "    'book_id': unique_book_id,\n",
    "    'mapped_book_id': pd.RangeIndex(len(unique_book_id))\n",
    "    })\n",
    "print(\"Mapping of book IDs to consecutive values:\")\n",
    "print(\"===========================================\")\n",
    "print(unique_book_id.head())\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
      "        [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]])\n"
     ]
    }
   ],
   "source": [
    "df_ratings = df_ratings.merge(unique_user_id, on='user_id')\n",
    "df_ratings = df_ratings.merge(unique_book_id, on='book_id')\n",
    "\n",
    "# With this, we are ready to create the edge_index representation in COO format\n",
    "# following the PyTorch Geometric semantics:\n",
    "edge_index = torch.stack([\n",
    "    torch.tensor(df_ratings['mapped_user_id'].values), \n",
    "    torch.tensor(df_ratings['mapped_book_id'].values)]\n",
    "    , dim=0)\n",
    "\n",
    "print(edge_index[:, :10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4795 4795\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  user={ x=[4795, 3] },\n",
       "  book={ x=[10000, 384] },\n",
       "  (user, rates, book)={\n",
       "    edge_index=[2, 5000],\n",
       "    edge_label=[5000],\n",
       "  },\n",
       "  (book, rev_rates, user)={ edge_index=[2, 5000] }\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import HeteroData\n",
    "\n",
    "# Create the heterogeneous graph data object:\n",
    "data = HeteroData()\n",
    "\n",
    "# Add the user nodes:\n",
    "data['user'].x = torch.tensor(users_features,)  # (num_users, num_users_features)\n",
    "\n",
    "# Add the book nodes:\n",
    "data['book'].x = torch.tensor(titles_emb,)  # (num_books, num_books_features)\n",
    "\n",
    "# Add the rating edges:\n",
    "data['user', 'rates', 'book'].edge_index = edge_index  # (2, num_ratings)\n",
    "\n",
    "# Add the rating labels:\n",
    "rating = torch.from_numpy(df_ratings['rating'].values)\n",
    "data['user', 'rates', 'book'].edge_label = rating  # [num_ratings]\n",
    "\n",
    "# We also need to make sure to add the reverse edges from books to users\n",
    "# in order to let a GNN be able to pass messages in both directions.\n",
    "# We can leverage the `T.ToUndirected()` transform for this from PyG:\n",
    "data = T.ToUndirected()(data)\n",
    "\n",
    "# With the above transformation we also got reversed labels for the edges.\n",
    "# We remove them\n",
    "del data['book', 'rev_rates', 'user'].edge_label\n",
    "\n",
    "print(data['user'].num_nodes,len(unique_user_id))\n",
    "assert data['user'].num_nodes == len(unique_user_id)\n",
    "assert data['user', 'rates', 'book'].num_edges == len(df_ratings)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  user={ x=[4795, 3] },\n",
       "  book={ x=[10000, 384] },\n",
       "  (user, rates, book)={\n",
       "    edge_index=[2, 5000],\n",
       "    edge_label=[5000],\n",
       "  },\n",
       "  (book, rev_rates, user)={ edge_index=[2, 5000] }\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(HeteroData(\n",
       "   user={ x=[4795, 3] },\n",
       "   book={ x=[10000, 384] },\n",
       "   (user, rates, book)={\n",
       "     edge_index=[2, 3500],\n",
       "     edge_label=[7000],\n",
       "     edge_label_index=[2, 7000],\n",
       "   },\n",
       "   (book, rev_rates, user)={ edge_index=[2, 3500] }\n",
       " ),\n",
       " HeteroData(\n",
       "   user={ x=[4795, 3] },\n",
       "   book={ x=[10000, 384] },\n",
       "   (user, rates, book)={\n",
       "     edge_index=[2, 3500],\n",
       "     edge_label=[1500],\n",
       "     edge_label_index=[2, 1500],\n",
       "   },\n",
       "   (book, rev_rates, user)={ edge_index=[2, 3500] }\n",
       " ),\n",
       " HeteroData(\n",
       "   user={ x=[4795, 3] },\n",
       "   book={ x=[10000, 384] },\n",
       "   (user, rates, book)={\n",
       "     edge_index=[2, 4250],\n",
       "     edge_label=[1500],\n",
       "     edge_label_index=[2, 1500],\n",
       "   },\n",
       "   (book, rev_rates, user)={ edge_index=[2, 4250] }\n",
       " ))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data, val_data, test_data = T.RandomLinkSplit(\n",
    "    add_negative_train_samples=True,\n",
    "    num_val=0.15,\n",
    "    num_test=0.15,\n",
    "    edge_types=[('user', 'rates', 'book')],\n",
    "    rev_edge_types=[('book', 'rev_rates', 'user')],\n",
    ")(data)\n",
    "train_data, val_data, test_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (encoder): GraphModule(\n",
      "    (conv1): ModuleDict(\n",
      "      (user__rates__book): SAGEConv((-1, -1), 10, aggr=mean)\n",
      "      (book__rev_rates__user): SAGEConv((-1, -1), 10, aggr=mean)\n",
      "    )\n",
      "    (conv2): ModuleDict(\n",
      "      (user__rates__book): SAGEConv((-1, -1), 10, aggr=mean)\n",
      "      (book__rev_rates__user): SAGEConv((-1, -1), 10, aggr=mean)\n",
      "    )\n",
      "  )\n",
      "  (decoder): EdgeDecoder(\n",
      "    (lin1): Linear(in_features=20, out_features=10, bias=True)\n",
      "    (lin2): Linear(in_features=10, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.nn import SAGEConv, to_hetero\n",
    "\n",
    "class GNNEncoder(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv((-1, -1), hidden_channels)\n",
    "        self.conv2 = SAGEConv((-1, -1), out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "\n",
    "class EdgeDecoder(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.lin1 = torch.nn.Linear(2 * hidden_channels, hidden_channels)\n",
    "        self.lin2 = torch.nn.Linear(hidden_channels, 1)\n",
    "\n",
    "    def forward(self, z_dict, edge_label_index):\n",
    "        row, col = edge_label_index\n",
    "        z = torch.cat([z_dict['user'][row], z_dict['book'][col]], dim=-1)\n",
    "\n",
    "        z = self.lin1(z).relu()\n",
    "        z = self.lin2(z)\n",
    "        return z.view(-1)\n",
    "\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.encoder = GNNEncoder(hidden_channels, hidden_channels)\n",
    "        self.encoder = to_hetero(self.encoder, data.metadata(), aggr='sum')\n",
    "        self.decoder = EdgeDecoder(hidden_channels)\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict, edge_label_index):\n",
    "        z_dict = self.encoder(x_dict, edge_index_dict)\n",
    "        return self.decoder(z_dict, edge_label_index)\n",
    "\n",
    "\n",
    "model = Model(hidden_channels=10).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  user={ x=[4795, 3] },\n",
       "  book={ x=[10000, 384] },\n",
       "  (user, rates, book)={\n",
       "    edge_index=[2, 3500],\n",
       "    edge_label=[1500],\n",
       "    edge_label_index=[2, 1500],\n",
       "  },\n",
       "  (book, rev_rates, user)={ edge_index=[2, 3500] }\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import HGTLoader\n",
    "train_mask = torch.tensor([True] * train_data[\"user\"].x.shape[0], )\n",
    "train_loader = HGTLoader(\n",
    "    train_data,\n",
    "    num_samples=[1024] * 4,\n",
    "    shuffle=True,\n",
    "    batch_size=128,\n",
    "    input_nodes=(\"user\", train_mask),\n",
    ")\n",
    "\n",
    "val_loader = HGTLoader(\n",
    "    val_data,\n",
    "    num_samples=[1024] * 4,\n",
    "    shuffle=False,\n",
    "    batch_size=128,\n",
    "    input_nodes=(\"user\", torch.tensor([True] * val_data[\"user\"].x.shape[0], )),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loop\n",
    "def train(model, data_loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in tqdm(data_loader):\n",
    "        batch = batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(batch.x_dict, batch.edge_index_dict, batch['user', 'rates', 'book'].edge_label_index)\n",
    "        loss = criterion(pred, batch['user', 'rates', 'book'].edge_label.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / (len(data_loader.dataset) / 128)\n",
    "\n",
    "# Testing Loop\n",
    "def test(model, data_loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            batch = batch.to(device)\n",
    "            pred = model(batch.x_dict, batch.edge_index_dict, batch['user', 'rates', 'book'].edge_label_index)\n",
    "            loss = criterion(pred, batch['user', 'rates', 'book'].edge_label.float())\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / (len(data_loader.dataset) / 128)\n",
    "\n",
    "# Main training and testing routines\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train(model, train_loader, optimizer, criterion)\n",
    "    val_loss = test(model, val_loader, criterion)\n",
    "    \n",
    "    # val_loss = test(model, val_data, criterion)\n",
    "    print(f'Epoch: {epoch+1}, Training Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}')\n",
    "    val_losses.append(val_loss)\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "# Optionally, after training, you can evaluate your model on the test dataset\n",
    "# test_loss = test(model, test_data, criterion)\n",
    "# print(f'Test Loss: {test_loss:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loop\n",
    "def train(model, data, optimizer, criterion):\n",
    "    model.train()\n",
    "    if device != 'cpu':\n",
    "        data = data.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    pred = model(data.x_dict, data.edge_index_dict, data['user', 'rates', 'book'].edge_label_index)\n",
    "    loss = criterion(pred, data['user', 'rates', 'book'].edge_label.float())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    total_loss = loss.item()\n",
    "    return total_loss \n",
    "\n",
    "# Testing Loop\n",
    "def test(model, data, criterion):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        if device != 'cpu':\n",
    "            data = data.to(device)\n",
    "        pred = model(data.x_dict, data.edge_index_dict, data['user', 'rates', 'book'].edge_label_index)\n",
    "        loss = criterion(pred, data['user', 'rates', 'book'].edge_label.float())\n",
    "        total_loss = loss.item()\n",
    "    return total_loss\n",
    "\n",
    "# Main training and testing routines\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.005)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    for d in train_loader:\n",
    "        train_loss = train(model, train_data, optimizer, criterion)\n",
    "        val_loss = test(model, val_data, criterion)\n",
    "        print(f'Epoch: {epoch+1}, Training Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}')\n",
    "        train_losses.append(train_loss)\n",
    "        valid_losses.append(val_loss)\n",
    "\n",
    "# Optionally, after training, you can evaluate your model on the test dataset\n",
    "test_loss = test(model, test_data, criterion)\n",
    "print(f'Test Loss: {test_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = test(model, test_data, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Test Loss: {test_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Plot the training and validation losses\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(valid_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model \n",
    "torch.save(model.state_dict(), \"model.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation & metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(hidden_channels=10).to(device)\n",
    "model.load_state_dict(torch.load(\"model.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_review = model(test_data.x_dict, test_data.edge_index_dict, test_data['user', 'rates', 'book'].edge_label_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.boxplot(pred_review.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['user', 'rates', 'book'].edge_label_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['user', 'rates', 'book'].edge_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert tensors to numpy arrays\n",
    "user_ids_np = test_data['user', 'rates', 'book'].edge_label_index[0].numpy()\n",
    "book_ids_np = test_data['user', 'rates', 'book'].edge_label_index[1].numpy()\n",
    "ratings_np = test_data['user', 'rates', 'book'].edge_label.numpy()\n",
    "ratings_pred_np = pred_review.detach().numpy()\n",
    "\n",
    "# Create a dictionary with the data\n",
    "data = {\n",
    "    'user_id': user_ids_np,\n",
    "    'book_id': book_ids_np,\n",
    "    'rating': ratings_np, \n",
    "    'predicted_rating': ratings_pred_np\n",
    "}\n",
    "\n",
    "# Create a pandas DataFrame\n",
    "df_ratings = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "from evaluation_metrics import *\n",
    "\n",
    "k = 10\n",
    "top_k_recommendations = get_top_k_recommendations(df_ratings, k)\n",
    "actual_items = get_actual_items(df_ratings) # ground truth\n",
    "\n",
    "# Evaluate the recommendations\n",
    "mean_precision, mean_recall, mean_f1 = evaluate_recommendations(top_k_recommendations, actual_items, k)\n",
    "print(f\"Mean Precision@{k}: {mean_precision}\")\n",
    "print(f\"Mean Recall@{k}: {mean_recall}\")\n",
    "print(f\"Mean F1 Score@{k}: {mean_f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrix factorization:\n",
    "\n",
    "Mean Precision@10: 0.7722234424908242\n",
    "Mean Recall@10: 0.5475533441372822\n",
    "Mean F1 Score@10: 0.6128487333956821"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "todo\n",
    "visualization on how the data looks like\n",
    "\n",
    "\n",
    "report \n",
    "objective and motivation \n",
    "analysis of the data\n",
    "method: improving over matrix factorization baseline\n",
    "results\n",
    "future study: even an idea about how to use diversity"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "networkML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
