{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/santelmo/graph_RecSys/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch_geometric as pyg\n",
    "\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = 'mps'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['book_id', 'title', 'authors'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df_books = pd.read_csv('../data/books.csv')[['book_id', 'title', 'authors']]    # TODO: think about using also the columns\n",
    "\n",
    "# df_ratings = pd.read_csv('../data/ratings.csv').sample(500000)  # TODO: remove the sampling on the final run\n",
    "df_ratings = pd.read_csv('../data/ratings.csv')\n",
    "\n",
    "print(df_books.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5976479"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/santelmo/graph_RecSys/venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Create features\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2', device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 313/313 [00:04<00:00, 64.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Books features shape: torch.Size([10000, 384])\n"
     ]
    }
   ],
   "source": [
    "# Books features\n",
    "df_books[\"text_to_embed\"] = \"Title: \" + df_books[\"title\"] + \" Authors: \" + df_books[\"authors\"]\n",
    "with torch.no_grad():\n",
    "    titles_emb = model.encode(df_books['text_to_embed'].values, device=device, show_progress_bar=True, batch_size=32)\n",
    "    \n",
    "del model\n",
    "torch.cuda.empty_cache()    \n",
    "\n",
    "books_features = torch.tensor(titles_emb)\n",
    "print(\"Books features shape:\", books_features.shape)\n",
    "\n",
    "# Users features: as we don't have any information we will use random features\n",
    "# users_features = torch.rand(df_ratings['user_id'].nunique(), 768, device=device)\n",
    "# print(\"Users features shape:\", users_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding edges: 100%|██████████| 5976479/5976479 [03:59<00:00, 24939.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "degree centrality computed\n",
      "pagerank computed\n",
      "all metrics computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>degree</th>\n",
       "      <th>pagerank</th>\n",
       "      <th>average_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.647436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.957285</td>\n",
       "      <td>0.975597</td>\n",
       "      <td>0.853846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.838199</td>\n",
       "      <td>0.838433</td>\n",
       "      <td>0.692164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.495383</td>\n",
       "      <td>0.495060</td>\n",
       "      <td>0.830556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.635039</td>\n",
       "      <td>0.541783</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     degree  pagerank  average_rating\n",
       "1  1.000000  1.000000        0.647436\n",
       "2  0.957285  0.975597        0.853846\n",
       "4  0.838199  0.838433        0.692164\n",
       "6  0.495383  0.495060        0.830556\n",
       "8  0.635039  0.541783        0.642857"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# embedding users\n",
    "\n",
    "# # Create a bipartite graph\n",
    "B = nx.Graph()\n",
    "# Add nodes with the node attribute \"bipartite\"\n",
    "B.add_nodes_from(df_ratings['user_id'].unique(), bipartite=0)  # Users\n",
    "B.add_nodes_from(df_ratings['book_id'].unique(), bipartite=1)  # Books\n",
    "\n",
    "# Add edges between users and books\n",
    "for _, row in tqdm(df_ratings.iterrows(), total=df_ratings.shape[0], desc=\"Adding edges\"):\n",
    "    B.add_edge(row['user_id'], row['book_id'], weight=row['rating'])\n",
    "\n",
    "# Compute metrics\n",
    "centrality = nx.degree_centrality(B)\n",
    "print('degree centrality computed')\n",
    "pagerank = nx.pagerank(B, weight='weight')\n",
    "print('pagerank computed')\n",
    "average_rating = df_ratings.groupby('user_id')['rating'].mean()\n",
    "print('all metrics computed')\n",
    "\n",
    "# # Prepare feature vectors for users\n",
    "features = pd.DataFrame(index=df_ratings['user_id'].unique())\n",
    "features['degree'] = [centrality[node] for node in features.index]\n",
    "features['pagerank'] = [pagerank[node] for node in features.index]\n",
    "features['average_rating'] = [average_rating.get(node, 0) for node in features.index]  # Add average ratings\n",
    "\n",
    "# # Normalize features\n",
    "scaler = MinMaxScaler()\n",
    "features_scaled = pd.DataFrame(scaler.fit_transform(features), index=features.index, columns=features.columns)\n",
    "\n",
    "# # Display the normalized features\n",
    "users_features = features_scaled.to_numpy(dtype=np.float32)\n",
    "\n",
    "features_scaled.head() \n",
    "\n",
    "# aprox 2 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>text_to_embed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>258</td>\n",
       "      <td>5</td>\n",
       "      <td>The Shadow of the Wind (The Cemetery of Forgot...</td>\n",
       "      <td>Carlos Ruiz Zafón, Lucia Graves</td>\n",
       "      <td>Title: The Shadow of the Wind (The Cemetery of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4081</td>\n",
       "      <td>4</td>\n",
       "      <td>I am Charlotte Simmons</td>\n",
       "      <td>Tom Wolfe</td>\n",
       "      <td>Title: I am Charlotte Simmons Authors: Tom Wolfe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>260</td>\n",
       "      <td>5</td>\n",
       "      <td>How to Win Friends and Influence People</td>\n",
       "      <td>Dale Carnegie</td>\n",
       "      <td>Title: How to Win Friends and Influence People...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>9296</td>\n",
       "      <td>5</td>\n",
       "      <td>The Drama of the Gifted Child: The Search for ...</td>\n",
       "      <td>Alice  Miller, Ruth Ward</td>\n",
       "      <td>Title: The Drama of the Gifted Child: The Sear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2318</td>\n",
       "      <td>3</td>\n",
       "      <td>The Millionaire Next Door: The Surprising Secr...</td>\n",
       "      <td>Thomas J. Stanley, William D. Danko</td>\n",
       "      <td>Title: The Millionaire Next Door: The Surprisi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  book_id  rating  \\\n",
       "0        1      258       5   \n",
       "1        2     4081       4   \n",
       "2        2      260       5   \n",
       "3        2     9296       5   \n",
       "4        2     2318       3   \n",
       "\n",
       "                                               title  \\\n",
       "0  The Shadow of the Wind (The Cemetery of Forgot...   \n",
       "1                             I am Charlotte Simmons   \n",
       "2            How to Win Friends and Influence People   \n",
       "3  The Drama of the Gifted Child: The Search for ...   \n",
       "4  The Millionaire Next Door: The Surprising Secr...   \n",
       "\n",
       "                               authors  \\\n",
       "0      Carlos Ruiz Zafón, Lucia Graves   \n",
       "1                            Tom Wolfe   \n",
       "2                        Dale Carnegie   \n",
       "3             Alice  Miller, Ruth Ward   \n",
       "4  Thomas J. Stanley, William D. Danko   \n",
       "\n",
       "                                       text_to_embed  \n",
       "0  Title: The Shadow of the Wind (The Cemetery of...  \n",
       "1   Title: I am Charlotte Simmons Authors: Tom Wolfe  \n",
       "2  Title: How to Win Friends and Influence People...  \n",
       "3  Title: The Drama of the Gifted Child: The Sear...  \n",
       "4  Title: The Millionaire Next Door: The Surprisi...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge the two dataframes keeping user_id, book_id, rating, title, authors\n",
    "df_ratings = pd.merge(df_ratings, df_books, on='book_id')\n",
    "df_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping of user IDs to consecutive values:\n",
      "==========================================\n",
      "   user_id  mapped_user_id\n",
      "0        1               0\n",
      "1        2               1\n",
      "2        4               2\n",
      "3        6               3\n",
      "4        8               4\n",
      "\n",
      "Mapping of book IDs to consecutive values:\n",
      "===========================================\n",
      "   book_id  mapped_book_id\n",
      "0      258               0\n",
      "1     4081               1\n",
      "2      260               2\n",
      "3     9296               3\n",
      "4     2318               4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a mapping from the user_id to a unique consecutive value in the range [0, num_users]:\n",
    "unique_user_id = df_ratings['user_id'].unique()\n",
    "unique_user_id = pd.DataFrame(data={\n",
    "    'user_id': unique_user_id, \n",
    "    'mapped_user_id': pd.RangeIndex(len(unique_user_id))\n",
    "    })\n",
    "print(\"Mapping of user IDs to consecutive values:\")\n",
    "print(\"==========================================\")\n",
    "print(unique_user_id.head())\n",
    "print()\n",
    "\n",
    "# Create a mapping from the book_id to a unique consecutive value in the range [0, num_books]:\n",
    "unique_book_id = df_ratings['book_id'].unique()\n",
    "unique_book_id = pd.DataFrame(data={\n",
    "    'book_id': unique_book_id,\n",
    "    'mapped_book_id': pd.RangeIndex(len(unique_book_id))\n",
    "    })\n",
    "print(\"Mapping of book IDs to consecutive values:\")\n",
    "print(\"===========================================\")\n",
    "print(unique_book_id.head())\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]])\n"
     ]
    }
   ],
   "source": [
    "df_ratings = df_ratings.merge(unique_user_id, on='user_id')\n",
    "df_ratings = df_ratings.merge(unique_book_id, on='book_id')\n",
    "\n",
    "# With this, we are ready to create the edge_index representation in COO format\n",
    "# following the PyTorch Geometric semantics:\n",
    "edge_index = torch.stack([\n",
    "    torch.tensor(df_ratings['mapped_user_id'].values), \n",
    "    torch.tensor(df_ratings['mapped_book_id'].values)]\n",
    "    , dim=0)\n",
    "\n",
    "print(edge_index[:, :10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53424 53424\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  user={ x=[53424, 3] },\n",
       "  book={ x=[10000, 384] },\n",
       "  (user, rates, book)={\n",
       "    edge_index=[2, 5976479],\n",
       "    edge_label=[5976479],\n",
       "  },\n",
       "  (book, rev_rates, user)={ edge_index=[2, 5976479] }\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import HeteroData\n",
    "\n",
    "# Create the heterogeneous graph data object:\n",
    "data = HeteroData()\n",
    "\n",
    "# Add the user nodes:\n",
    "data['user'].x = torch.tensor(users_features,)  # (num_users, num_users_features)\n",
    "\n",
    "# Add the book nodes:\n",
    "data['book'].x = torch.tensor(titles_emb,)  # (num_books, num_books_features)\n",
    "\n",
    "# Add the rating edges:\n",
    "data['user', 'rates', 'book'].edge_index = edge_index  # (2, num_ratings)\n",
    "\n",
    "# Add the rating labels:\n",
    "rating = torch.from_numpy(df_ratings['rating'].values)\n",
    "data['user', 'rates', 'book'].edge_label = rating  # [num_ratings]\n",
    "\n",
    "# We also need to make sure to add the reverse edges from books to users\n",
    "# in order to let a GNN be able to pass messages in both directions.\n",
    "# We can leverage the `T.ToUndirected()` transform for this from PyG:\n",
    "data = T.ToUndirected()(data)\n",
    "\n",
    "# With the above transformation we also got reversed labels for the edges.\n",
    "# We remove them\n",
    "del data['book', 'rev_rates', 'user'].edge_label\n",
    "\n",
    "print(data['user'].num_nodes,len(unique_user_id))\n",
    "assert data['user'].num_nodes == len(unique_user_id)\n",
    "assert data['user', 'rates', 'book'].num_edges == len(df_ratings)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  user={ x=[53424, 3] },\n",
       "  book={ x=[10000, 384] },\n",
       "  (user, rates, book)={\n",
       "    edge_index=[2, 5976479],\n",
       "    edge_label=[5976479],\n",
       "  },\n",
       "  (book, rev_rates, user)={ edge_index=[2, 5976479] }\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(HeteroData(\n",
       "   user={ x=[53424, 3] },\n",
       "   book={ x=[10000, 384] },\n",
       "   (user, rates, book)={\n",
       "     edge_index=[2, 4183537],\n",
       "     edge_label=[4183537],\n",
       "     edge_label_index=[2, 4183537],\n",
       "   },\n",
       "   (book, rev_rates, user)={ edge_index=[2, 4183537] }\n",
       " ),\n",
       " HeteroData(\n",
       "   user={ x=[53424, 3] },\n",
       "   book={ x=[10000, 384] },\n",
       "   (user, rates, book)={\n",
       "     edge_index=[2, 4183537],\n",
       "     edge_label=[1792942],\n",
       "     edge_label_index=[2, 1792942],\n",
       "   },\n",
       "   (book, rev_rates, user)={ edge_index=[2, 4183537] }\n",
       " ),\n",
       " HeteroData(\n",
       "   user={ x=[53424, 3] },\n",
       "   book={ x=[10000, 384] },\n",
       "   (user, rates, book)={\n",
       "     edge_index=[2, 5080008],\n",
       "     edge_label=[1792942],\n",
       "     edge_label_index=[2, 1792942],\n",
       "   },\n",
       "   (book, rev_rates, user)={ edge_index=[2, 5080008] }\n",
       " ))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data, val_data, test_data = T.RandomLinkSplit(\n",
    "    add_negative_train_samples=False,\n",
    "    num_val=0.15,\n",
    "    num_test=0.15,\n",
    "    edge_types=[('user', 'rates', 'book')],\n",
    "    rev_edge_types=[('book', 'rev_rates', 'user')],\n",
    ")(data)\n",
    "train_data, val_data, test_data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **NOTE:**\n",
    "To be more specific:\n",
    "* At **training** time:\n",
    "  * $\\text{training supervision edges} = \\text{training message passing edges}$ <br>\n",
    "* At **validation** time:\n",
    "  * $\\text{validation message passing edges} = \\text{training message passing edges} = \\text{training supervision edges}$ <br>\n",
    "  * $\\text{validation supervision edges} \\notin \\text{training supervision edges}$: disjoint with training supervision edges <br>\n",
    "\n",
    "* At **test** time:\n",
    "  * $\\text{test message passing edges} = \\text{validation supervison edges} + \\text{training supervision edges}$ <br>\n",
    "  * $\\text{test supervision edges} \\notin \\lbrace \\text{training supervision edges}, \\text{valid supervision edges} \\rbrace$: disjoint with training supervision edges and validation supervision edges. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import SAGEConv, to_hetero\n",
    "from torch import Tensor\n",
    "\n",
    "class GNNEncoder(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv((-1, -1), hidden_channels)\n",
    "        self.conv2 = SAGEConv((-1, -1), out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # Takes the edge_index (not the edge_label_index) as input, and performs\n",
    "        # message passing on the graph.\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "\n",
    "class EdgeDecoder(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x_user: Tensor, x_book: Tensor, edge_label_index):     \n",
    "        # NEW VERSION (simplified)\n",
    "        row, col = edge_label_index\n",
    "\n",
    "        # Apply dot-product to get a prediction per supervision edge:\n",
    "        return (x_user[row] * x_book[col]).sum(dim=-1)\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels: int, data: HeteroData):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.book_lin = torch.nn.Linear(384, hidden_channels)\n",
    "        self.user_emb = torch.nn.Embedding(data[\"user\"].num_nodes, hidden_channels)\n",
    "        self.book_emb = torch.nn.Embedding(data[\"book\"].num_nodes, hidden_channels)\n",
    "        \n",
    "        self.encoder = GNNEncoder(hidden_channels, hidden_channels)\n",
    "        self.encoder = to_hetero(self.encoder, data.metadata(), aggr='sum')\n",
    "        self.decoder = EdgeDecoder(hidden_channels)\n",
    "\n",
    "    def forward(self, data: HeteroData):\n",
    "        # This is completely ignoring the user features and only caring about the book features.\n",
    "        x_dict = {\n",
    "          \"user\": self.user_emb(data[\"user\"].n_id),\n",
    "          \"book\": self.book_lin(data[\"book\"].x) + self.book_emb(data[\"book\"].n_id),\n",
    "        }\n",
    "                \n",
    "        # `x_dict` holds feature matrices of all node types\n",
    "        # `edge_index_dict` holds all edge indices of all edge types\n",
    "        x_dict = self.encoder(x_dict, data.edge_index_dict)\n",
    "        return self.decoder(\n",
    "            x_dict[\"user\"],\n",
    "            x_dict[\"book\"],\n",
    "            data[\"user\", \"rates\", \"book\"].edge_label_index,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (book_lin): Linear(in_features=384, out_features=64, bias=True)\n",
      "  (user_emb): Embedding(53424, 64)\n",
      "  (book_emb): Embedding(10000, 64)\n",
      "  (encoder): GraphModule(\n",
      "    (conv1): ModuleDict(\n",
      "      (user__rates__book): SAGEConv((-1, -1), 64, aggr=mean)\n",
      "      (book__rev_rates__user): SAGEConv((-1, -1), 64, aggr=mean)\n",
      "    )\n",
      "    (conv2): ModuleDict(\n",
      "      (user__rates__book): SAGEConv((-1, -1), 64, aggr=mean)\n",
      "      (book__rev_rates__user): SAGEConv((-1, -1), 64, aggr=mean)\n",
      "    )\n",
      "  )\n",
      "  (decoder): EdgeDecoder()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = Model(hidden_channels=64, data=data).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import LinkNeighborLoader\n",
    "\n",
    "# Define seed edges:\n",
    "edge_label_index = train_data[\"user\", \"rates\", \"book\"].edge_label_index\n",
    "edge_label = train_data[\"user\", \"rates\", \"book\"].edge_label\n",
    "\n",
    "train_loader = LinkNeighborLoader(\n",
    "    data=train_data,  # TODO\n",
    "    num_neighbors=[25, 25],  # TODO\n",
    "    neg_sampling_ratio=2,  # TODO\n",
    "    edge_label_index=((\"user\", \"rates\", \"book\"), edge_label_index),\n",
    "    edge_label=edge_label,\n",
    "    batch_size=4096,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "val_loader = LinkNeighborLoader(\n",
    "    data=val_data,  # TODO\n",
    "    num_neighbors=[25, 25],  # TODO\n",
    "    neg_sampling_ratio=2,  # TODO\n",
    "    edge_label_index=((\"user\", \"rates\", \"book\"), edge_label_index),\n",
    "    edge_label=edge_label,\n",
    "    batch_size=4096,\n",
    "    shuffle=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: 'cuda'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 001 - Estimated loss 2.6434264808864016: 100%|██████████| 1022/1022 [03:42<00:00,  4.59it/s]\n",
      "Validation 001: 100%|██████████| 1022/1022 [03:17<00:00,  5.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 2.1951655055545634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 002 - Estimated loss 2.0523059635507956: 100%|██████████| 1022/1022 [03:59<00:00,  4.27it/s]\n",
      "Validation 002: 100%|██████████| 1022/1022 [03:16<00:00,  5.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 1.9584298187481408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 003 - Estimated loss 1.9093362033425536: 100%|██████████| 1022/1022 [03:50<00:00,  4.44it/s]\n",
      "Validation 003:  30%|██▉       | 306/1022 [00:54<02:19,  5.15it/s]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "logging_steps = 15\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: '{device}'\")\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "for epoch in range(1, 10):\n",
    "    total_loss = total_examples = 0\n",
    "    \n",
    "    est_loss = float(\"inf\")\n",
    "    pbar = tqdm(enumerate(train_loader), desc=f\"Epoch {epoch:03d} - Estimated loss {est_loss}\", total=len(train_loader))\n",
    "    \n",
    "    for i, sampled_data in pbar:\n",
    "        optimizer.zero_grad()\n",
    "        batch = sampled_data.to(device)\n",
    "        pred = model.forward(batch)\n",
    "        loss = F.mse_loss(pred, batch[\"user\", \"rates\", \"book\"].edge_label.to(torch.float32))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += float(loss) * pred.numel()\n",
    "        total_examples += pred.numel()\n",
    "        \n",
    "        # Update progress bar\n",
    "        if i % logging_steps == 0:\n",
    "            est_loss = total_loss / total_examples\n",
    "            pbar.set_description(f\"Epoch {epoch:03d} - Estimated loss {est_loss}\")\n",
    "            train_losses.append(est_loss)\n",
    "            \n",
    "    # Run Validation\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        total_valid_loss = total_valid_examples = 0\n",
    "        for batch in tqdm(val_loader, desc=f\"Validation {epoch:03d}\"):\n",
    "            batch = batch.to(device)\n",
    "            pred = model.forward(batch)\n",
    "            loss = F.mse_loss(pred, batch[\"user\", \"rates\", \"book\"].edge_label.to(torch.float32))\n",
    "            \n",
    "            total_valid_loss += float(loss) * pred.numel()\n",
    "            total_valid_examples += pred.numel()\n",
    "        valid_loss = total_valid_loss / total_valid_examples\n",
    "        valid_losses.append(valid_loss)\n",
    "        print(f\"Validation loss: {valid_loss}\")\n",
    "        model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(train_losses, label=\"Train loss\")\n",
    "plt.plot(valid_losses, label=\"Validation loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "torch.save(model.state_dict(), \"new_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "networkML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
